{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recurrent Neural Network\n",
    "# Part 1 - Data Preprocessing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# Importing and cleaning the dataset\n",
    "GDP = pd.read_csv('GDP_only.csv')\n",
    "GDP.fillna(0,inplace=True)\n",
    "GDP = GDP.T\n",
    "GDP=np.array(GDP)\n",
    "for i in range(4,GDP.shape[0]):\n",
    "    itemindex = np.where(GDP[i,:]==('..'))\n",
    "    GDP[i,itemindex]=0\n",
    "    GDP1=GDP[i,:]\n",
    "    GDP1=GDP1.astype(np.float)\n",
    "    nonzeroindex = GDP1.nonzero()\n",
    "    Mean=np.mean(GDP1[nonzeroindex])\n",
    "    zeroindex=np.argwhere(GDP1 == 0)\n",
    "    GDP1[zeroindex]=Mean\n",
    "    GDP[i,:]=GDP1   \n",
    "BRA=np.argwhere(GDP == 'BRA') \n",
    "GDP_flatten=[]  \n",
    "for i in range(0,268):  \n",
    "    GDP_flatten=np.concatenate((GDP_flatten,GDP[4:,i]), axis=0)   \n",
    "Nvar=1\n",
    "windowsize=32;\n",
    "GDP_BRA=GDP[6:,26]\n",
    "# Feature Scaling\n",
    "Mean=GDP_BRA.mean()\n",
    "STD=GDP_BRA.std()\n",
    "MIN=abs(min([n for n in GDP_BRA if n<0]))\n",
    "MAX=max(GDP_BRA)+MIN\n",
    "GDP_BRA=(GDP_BRA-Mean)/STD\n",
    "GDP_BRA1=(GDP_BRA+MIN)/MAX\n",
    "# Creating a data structure with 8 timesteps and 1 output\n",
    "training_set=GDP_BRA1\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(windowsize, training_set.shape[0]):\n",
    "    X_train.append(training_set[i-windowsize:i])\n",
    "    y_train.append(training_set[i])\n",
    "X_train, y_train = np.array(X_train).astype('float32'), np.array(y_train).astype('float32')\n",
    "# Reshaping\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1)).astype('float32')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "batch = int((GDP[6:,26].shape[0]-windowsize))\n",
    "# Initialising the RNN\n",
    "regressor = Sequential()\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = int(16) , return_sequences = True, input_shape = (X_train.shape[1], Nvar)))\n",
    "regressor.add(Dropout(0.05))\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = int(32), return_sequences = True))\n",
    "regressor.add(Dropout(0.05))\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = int(16)))\n",
    "regressor.add(Dropout(0.05))\n",
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 1))\n",
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the RNN to the Training set\n",
    "regressor.fit(X_train, y_train, epochs = 50, batch_size = int(batch)) #100 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3 - Making the predictions and visualising the results\n",
    "GDP_BR=GDP[6:,26]#GDP[5:,26]=BRA\n",
    "GDP_BRA=(GDP_BRA-Mean)/STD\n",
    "GDP_BRA=(GDP_BR+MIN)/MAX\n",
    "GDP_BRA=GDP_BRA\n",
    "inputs = GDP_BRA\n",
    "years=GDP[6:,26].shape[0]-windowsize  #anos a serem previstos\n",
    "inputs1 = inputs[inputs.shape[0]-years-windowsize:]\n",
    "X_test = []\n",
    "for i in range(windowsize,inputs1.shape[0]):\n",
    "    X_test.append(inputs[i-windowsize:i])\n",
    "X_test = np.array(X_test).astype('float32')\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], Nvar))\n",
    "predicted_stock_price = regressor.predict(X_test)\n",
    "predicted_stock_price= predicted_stock_price\n",
    "predicted_stock_price=predicted_stock_price*MAX-MIN\n",
    "predicted_stock_price=predicted_stock_price*STD+Mean\n",
    "####################################\n",
    "real_stock_price=GDP_BR[GDP_BR.shape[0]-predicted_stock_price.shape[0]:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the results\n",
    "x_year=[]\n",
    "for i in range(len(predicted_stock_price)):\n",
    "    x_year.append(2019-len(predicted_stock_price)+i)  \n",
    "    \n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(x_year,real_stock_price, color = 'red', label = 'Real Brazil GDP')\n",
    "plt.plot(x_year,predicted_stock_price, color = 'blue', label = 'Predicted Brazil GDP')\n",
    "plt.ylim(0,8)    \n",
    "plt.xlim(2005, 2018)  \n",
    "plt.yticks(range(-5,9,1), [str(x) + \"%\" for x in range(-5, 9, 1)], fontsize=14)    \n",
    "plt.xticks(fontsize=14,rotation=45) \n",
    "plt.legend()\n",
    "for y in range(-4,9,1):    \n",
    "    plt.plot(range(2005, 2019), [y] * len(range(2005, 2019)), \"--\", lw=0.5, color=\"black\", alpha=0.3)   \n",
    "plt.tick_params(axis=\"both\", which=\"both\", bottom=\"off\", top=\"off\",labelbottom=\"on\", left=\"off\", right=\"off\", labelleft=\"on\") \n",
    "plt.title('Brazil GDP Prediction')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Brazil GDP growth')\n",
    "\n",
    "plt.savefig('chi.png',bbox_inches='tight', dpi=800)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the model to predict the next 4 years (dynamic forecasting)\n",
    "yhat =[]\n",
    "y=0\n",
    "X_use=[] \n",
    "for i in range(0,inputs[24:56].shape[0],1): \n",
    "  X_use.append(inputs[(24+i)])\n",
    "  \n",
    "\n",
    "for i in range(1,9,1):\n",
    "    X_imp = np.reshape(X_use, (1,32,1))\n",
    "    y=float(regressor.predict(X_imp))\n",
    "    yhat.append(y)\n",
    "    X_use.append(y)\n",
    "    X_use = X_use[1:]\n",
    "yhat=np.array(yhat)\n",
    "yhat=yhat*MAX-MIN\n",
    "yhat=yhat*STD+Mean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recurrent Neural Network\n",
    "# Part 1 - Data Preprocessing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "###################################################################\n",
    "# Importing and cleaning the dataset\n",
    "###################################################################\n",
    "\n",
    "GDP = pd.read_csv('GDP.csv')\n",
    "GDP = GDP.T\n",
    "GDP=np.array(GDP)\n",
    "  \n",
    "#change '..' to nan\n",
    "for r in range(GDP.shape[1]):\n",
    "    itemindex = np.where((GDP[:,r]==('..')))\n",
    "    GDP[itemindex,r]=np.nan\n",
    "GDP_COLUMNS=GDP[0,:]  \n",
    "GDP=GDP[5:,:].astype(np.float) #change strings to numbers\n",
    "\n",
    "#change 0 to nan\n",
    "zeroindex = []\n",
    "for t in range(GDP.shape[1]):\n",
    "    zeroindex = np.where((GDP[:,t] == (0)))\n",
    "    GDP[zeroindex,t]=np.nan\n",
    "       \n",
    "#remove rows with more than 30 years of invalid data\n",
    "to_keep=[]     \n",
    "for u in range(GDP.shape[1]):    \n",
    "    if (sum(np.isnan(GDP[:,u].astype(float)))<30):\n",
    "        to_keep.append(u)      \n",
    "GDP=GDP[:,to_keep]\n",
    "GDP_COLUMNS=GDP_COLUMNS[to_keep]  \n",
    "    \n",
    "#remove coluns with unvariable data \n",
    "to_keep=[]     \n",
    "for o in range(GDP.shape[1]):    \n",
    "    if np.unique(GDP[:,o]).shape[0]>4 :\n",
    "        to_keep.append(o)\n",
    "GDP=GDP[:,to_keep]\n",
    "\n",
    "\n",
    "GDP_COLUMNS=GDP_COLUMNS[to_keep] \n",
    "GDP_REAL_VALUES=GDP\n",
    "GDP1=GDP\n",
    "\n",
    "#inserting 5 np.nan in the end of each column to later making regression upon then\n",
    "a=list(GDP)\n",
    "b=[]\n",
    "for i in range(GDP.shape[1]):\n",
    "    b.append(np.nan)\n",
    " \n",
    "\n",
    "for j in range(5):\n",
    "    a.append(b)\n",
    "    \n",
    "a=np.array(a)\n",
    "GDP=a      \n",
    "GDP1=a               \n",
    "np.argwhere(GDP_COLUMNS=='GDP growth (annual %)')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making linear and exponential regression on missing data\n",
    "#the next lines figure out the regression with minimal error and uses it\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import random\n",
    "\n",
    "for i in range(GDP.shape[1]):\n",
    "    y_train_lin=GDP[:,i]\n",
    "    y_train_exp=GDP[:,i]\n",
    "    x_train_lin=np.argwhere(~np.isnan(y_train_lin))\n",
    "    if (x_train_lin.shape[0]<62): #check if there is data to be completed\n",
    "        x_train_lin=np.argwhere(~np.isnan(y_train_lin))#index of not missing data\n",
    "        x_test_lin=np.argwhere(np.isnan(y_train_lin)) #index missing data\n",
    "        y_train_lin=y_train_lin[x_train_lin]#y of not missing data\n",
    "        lm = LinearRegression() #making linear regression\n",
    "        lm.fit(x_train_lin,y_train_lin)#fiting linear regression\n",
    "        predictions_lin = lm.predict(x_test_lin) #using the model to fill missing data\n",
    "        y_hat_lin = lm.predict(x_train_lin) #comparing the model to true values\n",
    "        error_lin=y_hat_lin-y_train_lin #comparing the model to true values\n",
    "        y_hat_dev_lin=[]\n",
    "        for k in range(len(x_test_lin)):\n",
    "            y_hat_dev_lin.append(random.uniform(-error_lin.std()*1.4,error_lin.std()*1.4)) #puting noise in data to be filled proportional to the standard deviation from true values\n",
    "        y_validation_lin=[]    \n",
    "        for e in range(len(x_train_lin)):\n",
    "            y_validation_lin.append(random.uniform(-error_lin.std()*1.4,error_lin.std()*1.4)) #puting noise in validation data to be filled proportional to the standard deviation from true values   \n",
    "        y_hat_dev_lin=np.array(y_hat_dev_lin) \n",
    "        y_validation_lin=np.array(y_validation_lin)\n",
    "        predictions_lin=np.array(predictions_lin)\n",
    "        y_validation_lin=np.reshape(y_validation_lin,(len(y_validation_lin), 1))\n",
    "        y_hat_dev_lin=np.reshape(y_hat_dev_lin,(len(x_test_lin), 1))  \n",
    "        y_validation_lin=abs(y_hat_lin+y_validation_lin)\n",
    "        y_hat_noise_lin=abs(predictions_lin+y_hat_dev_lin)\n",
    "        #plt.plot(x_test_lin,predictions_lin)\n",
    "        #plt.plot(x_train_lin,y_hat_lin)\n",
    "        #plt.scatter(x_train_lin,y_validation_lin)\n",
    "        #plt.scatter(x_train_lin,y_train_lin)\n",
    "        #plt.scatter(x_test_lin,y_hat_noise_lin)\n",
    "    \n",
    "        true_error_lin=(y_validation_lin-y_train_lin)\n",
    "        squared_error_lin=true_error_lin**2\n",
    "        lin_error=sum(squared_error_lin)\n",
    "        #linear_regression_r2_score=r2_score(y_train,y_validation)\n",
    "    \n",
    "        #exponential regression\n",
    "        x_train_exp=np.argwhere(~np.isnan(y_train_exp))\n",
    "        if not(any(y_train_exp[x_train_exp]<0)):  #check if there is negative values \n",
    "            x_train_exp=np.argwhere(~np.isnan(y_train_exp))\n",
    "            x_test_exp=np.argwhere(np.isnan(y_train_exp))\n",
    "            y_train_exp=y_train_exp[x_train_exp]\n",
    "            y_train_exp=np.log(y_train_exp)\n",
    "            lm = LinearRegression()\n",
    "            lm.fit(x_train_exp,y_train_exp)\n",
    "            predictions_exp = lm.predict(x_test_exp)\n",
    "            y_hat_exp = lm.predict(x_train_exp)\n",
    "            error_exp=y_hat_exp-y_train_exp\n",
    "            y_hat_dev_exp=[]\n",
    "            for j in range(len(x_test_exp)):\n",
    "                y_hat_dev_exp.append(random.uniform(-error_exp.std(),error_exp.std()))\n",
    "            y_validation_exp=[]    \n",
    "            for m in range(len(x_train_exp)):\n",
    "                y_validation_exp.append(random.uniform(-error_exp.std(),error_exp.std()))    \n",
    "            y_hat_dev_exp=np.array(y_hat_dev_exp) \n",
    "            y_validation_exp=np.array(y_validation_exp)\n",
    "            predictions_exp=np.array(predictions_exp)\n",
    "            y_validation_exp=np.reshape(y_validation_exp,(len(y_validation_exp), 1))\n",
    "            y_hat_dev_exp=np.reshape(y_hat_dev_exp,(len(x_test_exp), 1))  \n",
    "            y_validation_exp=y_hat_exp+y_validation_exp\n",
    "            y_hat_noise_exp=predictions_exp+y_hat_dev_exp\n",
    "            #plt.plot(x_test_exp,predictions_exp)\n",
    "            #plt.plot(x_train_exp,y_hat_exp)\n",
    "            #plt.scatter(x_train_exp,y_validation_exp)\n",
    "            #plt.scatter(x_train_exp,y_train_exp)\n",
    "            #plt.scatter(x_test_exp,y_hat_noise_exp)\n",
    "            y_train_exp=GDP[:,i]\n",
    "            #plt.scatter(x_train_exp,y_train_exp[x_train_exp])\n",
    "            #plt.scatter(x_train_exp,np.exp(y_validation_exp))\n",
    "            #plt.scatter(x_test_exp,np.exp(y_hat_noise_exp))\n",
    "            #plt.plot(x_train_exp,np.exp(y_hat_exp))\n",
    "            true_error_exp=(np.exp(y_hat_exp)-np.exp(y_validation_exp))\n",
    "            squared_error_exp=true_error_exp**2\n",
    "            exp_error=sum(squared_error_exp)\n",
    "            #exp_regression_r2_score=r2_score(y_train[x_train_exp],y_validation_exp)\n",
    "        if (any(y_train_exp[x_train_exp]<0)): \n",
    "            GDP1[x_test_lin,i]=y_hat_noise_lin\n",
    "            \n",
    "        if exp_error<=lin_error: #check wich regression has the smallest error\n",
    "            #GDP[x_test_exp,i]=np.exp(y_haceedt_noise_exp)\n",
    "            GDP1[x_test_exp,i]=np.exp(y_hat_noise_exp)\n",
    "        if exp_error>lin_error:\n",
    "            #GDP[x_test_lin,i]=np.exp(y_hat_noise_lin)\n",
    "            GDP1[x_test_lin,i]=y_hat_noise_lin\n",
    "            #plt.scatter(range(57),GDP[:,i])\n",
    "            #plt.scatter(range(57),GDP1[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nvar=GDP1.shape[1] #Number of variables used as input in the model\n",
    "windowsize=12; #Time window in wich the model will look \n",
    "GDP_BRA=GDP1\n",
    "\n",
    "# Feature Scaling\n",
    "Mean = []\n",
    "STD = []\n",
    "MAX = [] \n",
    "MIN = []\n",
    "for i in range(GDP.shape[1]):\n",
    "    Mean.append(GDP_BRA[:,i].mean())\n",
    "    STD.append(GDP_BRA[:,i].std())\n",
    "    GDP_BRA[:,i]=(GDP_BRA[:,i]-Mean[i])/STD[i]\n",
    "    MAX.append(max(GDP_BRA[:,i]))\n",
    "    MIN.append(abs(min(GDP_BRA[:,i])))\n",
    "    GDP_BRA[:,i]=(GDP_BRA[:,i]+MIN[i])/(MAX[i]+MIN[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a data structure with 32 timesteps (x) for each 1 output (y)\n",
    "data_set=GDP_BRA\n",
    "X_set = []\n",
    "y_set = []\n",
    "GDP_index=int(np.argwhere(GDP_COLUMNS=='GDP growth (annual %)'))       \n",
    "for years in range(windowsize, data_set.shape[0]-5):\n",
    "    X_set.append(data_set[years-windowsize:years,:])       \n",
    "for years in range(windowsize, data_set.shape[0]-5):\n",
    "    y_set.append(data_set[years,GDP_index])\n",
    "        \n",
    "X_set, y_set = np.array(X_set), np.array(y_set)\n",
    "# Reshaping\n",
    "y_train=y_set\n",
    "\n",
    "X_train = np.reshape(X_set, (X_set.shape[0],windowsize,Nvar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "batch = 1\n",
    "# Initialising the RNN\n",
    "regressor = Sequential()\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = int(X_train.shape[2]/windowsize) , return_sequences = True, input_shape = (X_train.shape[1], Nvar)))\n",
    "regressor.add(Dropout(0.2))\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = int(X_train.shape[2]/windowsize), return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = int(X_train.shape[2]/windowsize)))\n",
    "regressor.add(Dropout(0.2))\n",
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 1))\n",
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(X_train, y_train, epochs = 100, batch_size = 32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set=GDP_BRA\n",
    "\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "GDP_index=int(np.argwhere(GDP_COLUMNS=='GDP growth (annual %)'))       \n",
    "for years in range(data_set.shape[0]-5,data_set.shape[0]):\n",
    "        X_test.append(data_set[years-windowsize:years,:])\n",
    "        \n",
    "for years in range(data_set.shape[0]-5, data_set.shape[0]):\n",
    "        Y_test.append(data_set[years,GDP_index])\n",
    "X_test, Y_test  = np.array(X_test), np.array(Y_test)\n",
    "# Reshaping\n",
    "y_train=y_set\n",
    "\n",
    "X_test = np.reshape(X_test, (5,windowsize,Nvar))       \n",
    "\n",
    "predicted_GDP = regressor.predict(X_train)\n",
    "predicted_GDP=(predicted_GDP*(MAX[GDP_index]+MIN[GDP_index])-MIN[GDP_index]) \n",
    "predicted_GDP=predicted_GDP*STD[GDP_index]+Mean[GDP_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "real_GDP=GDP_REAL_VALUES[GDP_REAL_VALUES.shape[0]-len(predicted_GDP):,GDP_index]\n",
    "# Visualising the results\n",
    "x_year=[]\n",
    "X_init_year=1994\n",
    "X_final_Year=2018\n",
    "for i in range(len(predicted_GDP)):\n",
    "    x_year.append(X_final_Year+1-len(predicted_GDP)+i)   \n",
    "plt.figure(figsize=(20,10))\n",
    "plt.ylim(int(min(min(real_GDP),min(predicted_GDP)))-1,int(max(max(real_GDP),max(predicted_GDP)))-3)   \n",
    "plt.xlim(X_init_year,X_final_Year)  \n",
    "plt.yticks(range(-5,10,1), [str(x) + \"%\" for x in range(-5, 10, 1)], fontsize=14)    \n",
    "plt.xticks(fontsize=12,rotation=45) \n",
    "for y in range(-4,10,1):    \n",
    "    plt.plot(range(X_init_year,X_final_Year+1), [y] * len(range(X_init_year,X_final_Year+1)), \"--\", lw=0.5, color=\"black\", alpha=0.3) \n",
    "plt.plot(x_year,real_GDP, color = 'red', label = 'Real Brazil GDP')\n",
    "plt.plot(x_year,predicted_GDP, color = 'blue', label = 'Predicted Brazil GDP')\n",
    "plt.tick_params(axis=\"both\", which=\"both\", bottom=\"off\", top=\"off\",labelbottom=\"on\", left=\"off\", right=\"off\", labelleft=\"on\") \n",
    "plt.title('Brazil GDP Prediction')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Brazil GDP growth')\n",
    "plt.legend(loc='lower center', frameon=True)\n",
    "plt.savefig('CaboVerde-18.png',bbox_inches='tight', dpi=800)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
